{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a57bfdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/mouly/opt/anaconda3/lib/python3.8/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/mouly/opt/anaconda3/lib/python3.8/site-packages (from opencv-python) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73985060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package imported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "print('Package imported')\n",
    "img = cv2.imread('Mouly.JPG')\n",
    "cv2.imshow('Output', img)\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded19d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('Cute Cat - 3092.mp4')\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow('Video', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('m'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd67a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow('Video', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('m'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f987598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "img = cv2.imread('Mouly.JPG')\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray,(7,7), 0)\n",
    "imgCanny = cv2.Canny(img, 150, 200)\n",
    "imgDilation = cv2.dilate(imgCanny, kernel, iterations = 3)\n",
    "imgerode = cv2.erode(imgDilation, kernel, iterations = 1)\n",
    "cv2.imshow('GRAY Image', imgGray)\n",
    "cv2.imshow('Blur Image', imgBlur)\n",
    "cv2.imshow('Canny Image', imgCanny)\n",
    "cv2.imshow('Dilate Image', imgDilation)\n",
    "cv2.imshow('Eroder Image', imgerode)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf172f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openCV convention: x axis is same, y axis is towards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 4000, 3)\n",
      "(400, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "#resizing image:\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('Mouly.JPG')\n",
    "print(img.shape)                  #(6000---> weight, 4000 ---> height, 3---> BGR)\n",
    "imgResize = cv2.resize(img, (200, 400))  #here, the weight comes first, then the height\n",
    "print(imgResize.shape)            #(400, 200, 3)\n",
    "imgCropped = img[0:2000, 200:900]            #here, the height comes first                \n",
    "cv2.imshow('Image', img)\n",
    "cv2.imshow('Resize Image', imgResize)\n",
    "cv2.imshow('Cropped Image', imgCropped)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53ce083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shapes and texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98b4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "#we will use numpy library to create our img matrix\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#img = np.zeros((512, 512))   #it will show a black img, which is gray scale image.\n",
    "#print(img.shape)\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "#print(img)       #it shows the matrix\n",
    "#img[:] = 255, 0, 0     #it colors the whole image blue\n",
    "img[200:600, 100: 500] = 255, 0, 0   #it shows only the portion as blue\n",
    "print(img)\n",
    "\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca107c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a line\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.line(img, (0,0), (400, 400), (0,255,0), 3) #(0,0) starting point, (400, 400) end point, (0,255,0) color, 3--> thickness\n",
    "#for creating the whole line in picture, we use 'img.shape()'\n",
    "cv2.line(img,(0,0), (img.shape[1], img.shape[0],), (0, 255, 0), 3) #first width, then height\n",
    "cv2.rectangle(img,(0,0), (250,350),(0,0,255), 2)\n",
    "#cv2.rectangle(img,(0,0), (250,350),(0,0,255), cv2.FILLED) #for filling rectangle\n",
    "cv2.circle(img,(400,50), 30, (255, 255, 0), 5) #(400, 50) center point, 30 --> radius, color, thickness\n",
    "cv2.putText(img, 'Mouly', (200, 200), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 150,0), 2) #1 --> scale(makes big-small), 2--> thickness\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap prespective\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('openCVking.jpg')\n",
    "\n",
    "width, height = 250, 350\n",
    "points = np.float32([[345,122],[580, 82],[409, 450],[636, 409]]) #we are taking four edges points from paints\n",
    "points2 = np.float32([[0,0],[width, 0], [0,height], [width, height]])\n",
    "matrix = cv2.getPerspectiveTransform(points, points2)\n",
    "imgOutput = cv2.warpPerspective(img, matrix,(width, height))\n",
    "\n",
    "cv2.imshow('Cards', img)\n",
    "cv2.imshow('Output', imgOutput)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a37cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining images(use stack)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('Mouly.JPG')\n",
    "imgHor = np.hstack((img,img,img))\n",
    "imgVer = np.vstack((img,img))\n",
    "\n",
    "cv2.imshow('Horizontal',imgHor)\n",
    "cv2.imshow('Vertical',imgVer)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLOR DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47973fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('Mouly.JPG')\n",
    "\n",
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('HSV', imgHSV)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now will create trackbars for adjusting this HSV colors.\n",
    "import cv2\n",
    "path = 'Mouly.JPG'\n",
    "\n",
    "cv2.namedWindow('TrackBars')\n",
    "cv2.resize(\"TrackBars\", 640, 240)\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread(path)\n",
    "\n",
    "imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('HSV', imgHSV)\n",
    "cv2.waitKey(0)\n",
    "#will finish it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3203e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FACE DETECTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') #this is a default file that we are using \n",
    "img = cv2.imread('Mouly.JPG')\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(imgGray, 1.1, 4) #we are going to find face using it\n",
    "\n",
    "#going to create a bounding box around the faces that we detected and put a rectangle around them\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w, y+h), (225, 0, 0), 4)\n",
    "\n",
    "cv2.imshow('Result', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " #this is a default file that we are using \n",
    "cap = cv2.VideoCapture('sampleTesting.mp4')\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        p = x+(w//2)\n",
    "        q = y+(h//2)\n",
    "        var = f'{p} , {q}'\n",
    "        cv2.rectangle(img,(x,y),(x+w, y+h), (0, 255, 0), 4)\n",
    "        cv2.line(img, (1080//2,1920//2), (1080, 1920), (0,255,0), 3)\n",
    "        cv2.putText(img, var, (x+200, y+200), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 150,0), 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    cv2.imshow('Video', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('m'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb4211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image to grayscale image\n",
    "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# convert the grayscale image to binary image\n",
    "ret,thresh = cv2.threshold(gray_image,127,255,0)\n",
    " \n",
    "# calculate moments of binary image\n",
    "M = cv2.moments(thresh)\n",
    " \n",
    "# calculate x,y coordinate of center\n",
    "cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "cY = int(M[\"m01\"] / M[\"m00\"])\n",
    " \n",
    "# put text and highlight the center\n",
    "cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "cv2.putText(img, \"centroid\", (cX - 25, cY - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    " \n",
    "# display the image\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc913e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. #Write a python program to detect your face and deviation of your face from the center of the frame using OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ecacf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "cap = cv2.VideoCapture(0) \n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') #importing xml file\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "     \n",
    "    for (x, y, width, height) in faces:\n",
    "        pos1 = x+(width//2)\n",
    "        pos2 = y+(height//2)\n",
    "        w_shape = img.shape[1]//2\n",
    "        h_shape = img.shape[0]//2\n",
    "        eqn1 = pos1 - w_shape\n",
    "        eqn2 = pos2 - h_shape\n",
    "        #calculating the distance of the face\n",
    "        distance = math.sqrt((eqn1)**2 + (eqn2)**2)\n",
    "        #defining the rectangle\n",
    "        cv2.rectangle(img,(x,y),(x+width, y+height), (0, 255, 0), 4)\n",
    "        #line for indicating the center of the face\n",
    "        cv2.line(img, (w_shape, h_shape), (pos1, pos2), (0,255,0), 3)\n",
    "        #for face positions\n",
    "        variable = 'Center'\n",
    "        if eqn2 < 0:\n",
    "            variable = 'Upward'\n",
    "            if eqn1 > 0:\n",
    "                variable += 'Right'\n",
    "            else:\n",
    "                variable += 'Left'\n",
    "        elif eqn2 > 0:\n",
    "            variable = 'Downward'\n",
    "            if eqn1 > 0:\n",
    "                variable += 'Right'\n",
    "            else:\n",
    "                variable += 'Left'\n",
    "        #text for the distance\n",
    "        cv2.putText(img, 'Distance :'+ str(int(distance)),(x+100,y+100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 150,0), 2)\n",
    "                \n",
    "        #text for the position\n",
    "        cv2.putText(img, 'Position: '+ variable, (x+100, y+150), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 150,0), 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    cv2.imshow('Output', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('m'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90092eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcabab0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
